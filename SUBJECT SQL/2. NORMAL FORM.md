### Normalization Defination
Database Normalization is the Process of organizating Data to Minimize 
- Data Redundancy (DML QUERIES CAN BE SLOW)
- Data Duplication (DISK SPACE WASTAGE)
- Data Consistency (CREATE, UPDATE, DELETE)

Database Normalization is a step by step process.
Most Databases are in Third Normal Form (3NF) 
There are 6 Normal Forms, 1NF Thru 6NF

#### 1NF
1. The Data in Each Column should be Atomic (Math, Physics, Chemistry) 
	(PROBLEM WITH PARTIALLY UPDATE)
2. Table Does not Contain NO REAPEATING COLUMN GROUP (SUBJECT_MATH, SUBJECT_PHYSICS, SUBJECT_CHMESTRY)
3. Identity each Record UNIQUELY using PRIMARY KEY
- Eliminate duplicate columns from the same table.

#### 2NF
1. The Table meets all the Conditions of 1NF
2. Move REDUNDANT DATA to a Seperate Table (EMPLOYEE AND DEPARTEMENT) IS STORED IN SAME TABLE 
3. Create RELATIONSHIP between these tables using FOREIGN KEYS.
- remove partial dependencies.

#### 3NF
1. Meets all the conditions of 2NF
2. Does not contain columns (attributes) that are not fully dependent upon the PRIMARY KEY 
- Remove transitive dependencies.

#### BCNF (Boyce-Codd Normal Form):
1. A database table is in BCNF if and only if there are no non-trivial functional dependencies of attributes on anything other than a superset of a candidate key. BCNF is also sometimes referred to as 3.5NF.
2. (Student, Teacher, Subject) if Subject can be refer with Teacher then we don't have to Add SUBJECT within Student Table.

#### 4NF
1. Meets all the Condition of 3NF
2. No Columns has Array, Sets in a Cell (PROBLEM WITH PARTIALLY UPDATE)

- SUMARY In summary, BCNF is a level of normalization that focuses on eliminating non-trivial functional dependencies where the determinant is not a superkey. This helps in designing a database schema that minimizes redundancy and maintains data integrity.



### ADVANTAGE OF NORMALIZATION
We normalize tables in a database for several important reasons:
1. **Minimize Data Redundancy:** Normalization reduces data redundancy by organizing data into separate tables and eliminating duplicate information. This not only saves storage space but also ensures data consistency by reducing the risk of inconsistencies and errors.
2. **Improve Data Integrity:** Normalization helps maintain data integrity by preventing anomalies such as insertion, update, or deletion anomalies. With properly structured tables, data is less likely to become inconsistent or incorrect.
3. **Optimize Database Performance:** Well-normalized databases typically perform better because they require fewer resources to manage data. Query execution becomes more efficient, leading to faster and more responsive database operations.
4. **Facilitate Scalability:** Normalization makes it easier to expand and modify the database schema without disrupting existing data. This flexibility is essential as requirements change over time.
5. **Enhance Data Maintainability:** A normalized database is easier to maintain and update. Changes to data structures can be made with minimal impact on the overall system, making maintenance tasks more straightforward.
6. **Support Data Consistency:** By reducing redundancy and enforcing data integrity, normalization helps maintain a consistent and accurate representation of the real-world entities and relationships within the database.
7. **Improve Data Quality:** Normalization encourages the use of a standardized structure for data, making it easier to validate and cleanse data for quality assurance.

In summary, normalization is a fundamental technique in database design that aims to eliminate redundancy, improve data integrity, enhance performance, and make databases more scalable and maintainable. It ensures that data is well-structured, consistent, and efficient, which is essential for effective and reliable database systems.

